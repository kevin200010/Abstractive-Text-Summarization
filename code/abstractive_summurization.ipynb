{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0bc4533a01521e375ffa37256b9515278a7f12ae88345fd58eabf85b38ac557a5",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Text - Summarization using abstractive summarization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "###     we are going to use lstm encode-decode model for this. Abstractive methods select words based on semantic understanding, even those words did not appear in the source documents. It aims at producing important material in a new way. They interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### It can be correlated to the way human reads a text article or blog post and then summarizes in their own word.\n",
    "Input document → understand context → semantics → create own summary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem statement :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " generate a summary for long food reviews."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset  : https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"../Reviews.csv\" , nrows=100000)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "drops NA and duplicates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'] , inplace=True)\n",
    "data.dropna(axis=0 , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 88421 entries, 0 to 99999\nData columns (total 10 columns):\n #   Column                  Non-Null Count  Dtype \n---  ------                  --------------  ----- \n 0   Id                      88421 non-null  int64 \n 1   ProductId               88421 non-null  object\n 2   UserId                  88421 non-null  object\n 3   ProfileName             88421 non-null  object\n 4   HelpfulnessNumerator    88421 non-null  int64 \n 5   HelpfulnessDenominator  88421 non-null  int64 \n 6   Score                   88421 non-null  int64 \n 7   Time                    88421 non-null  int64 \n 8   Summary                 88421 non-null  object\n 9   Text                    88421 non-null  object\ndtypes: int64(5), object(5)\nmemory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Id  ...                                               Text\n",
       "0           1  ...  I have bought several of the Vitality canned d...\n",
       "1           2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2           3  ...  This is a confection that has been around a fe...\n",
       "3           4  ...  If you are looking for the secret ingredient i...\n",
       "4           5  ...  Great taffy at a great price.  There was a wid...\n",
       "...       ...  ...                                                ...\n",
       "99995   99996  ...  I just love it and will buy another box when I...\n",
       "99996   99997  ...  My late father in law used to have a rating sy...\n",
       "99997   99998  ...  This is my favorite brand of Korean ramen. It ...\n",
       "99998   99999  ...  I do like these noodles although, to say they ...\n",
       "99999  100000  ...  I love this noodle and have it once or twice a...\n",
       "\n",
       "[88421 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>99996</td>\n      <td>B000LQORDE</td>\n      <td>A2P7HIRYYWVOBD</td>\n      <td>Mason</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1254096000</td>\n      <td>yummy!</td>\n      <td>I just love it and will buy another box when I...</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>99997</td>\n      <td>B000LQORDE</td>\n      <td>A1K0ZH5MQFBA77</td>\n      <td>jennilight</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1250985600</td>\n      <td>Tastes like More!</td>\n      <td>My late father in law used to have a rating sy...</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>99998</td>\n      <td>B000LQORDE</td>\n      <td>A29FRN2O7LWINL</td>\n      <td>T. Tsai</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1237766400</td>\n      <td>Great ramen</td>\n      <td>This is my favorite brand of Korean ramen. It ...</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>99999</td>\n      <td>B000LQORDE</td>\n      <td>A9Q950IPXJR1D</td>\n      <td>Lynda \"casual customer\"</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1237161600</td>\n      <td>Spicy!!</td>\n      <td>I do like these noodles although, to say they ...</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>100000</td>\n      <td>B000LQORDE</td>\n      <td>A19W47CXJJP1MI</td>\n      <td>Amazonian Consumer</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1235088000</td>\n      <td>This spicy noodle cures my cold, upset stomach...</td>\n      <td>I love this noodle and have it once or twice a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>88421 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "source": [
    "### we drop unwanted symbol , charectors from dataset that do not affect the objective of our problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\",                                   \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had                                   not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                        \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",                                     \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                         \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I                                    will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                         \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\":                                    \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "\n",
    "8.Remove short words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"you'd\", 'whom', 'll', 'd', 'being', 'the', 'will', 'between', 'so', 'any', 'no', 'over', 'doesn', 'don', \"mightn't\", 'm', 're', 'my', 'is', 'by', 'into', 'on', 'shouldn', 'until', \"should've\", 'it', 'all', 'most', 'isn', 'weren', 'from', 'such', 'just', 'aren', 'his', 'has', 'wasn', 'too', \"wasn't\", 'its', 'o', 'both', 've', 'under', 'our', 'same', 'again', 'out', 'been', 'they', 'yourselves', \"needn't\", 'having', 'yours', 'him', 'who', 'ours', 'itself', 'here', 'does', 'further', 'should', 'now', \"didn't\", 'for', 'are', \"shan't\", 'i', 'while', \"isn't\", 'each', 'because', 'how', \"you're\", 'your', 'as', 'only', 'why', 'other', 'above', 'up', 'themselves', 'myself', 'did', 's', \"weren't\", \"that'll\", 'these', 'had', 'not', \"aren't\", 'own', \"you'll\", \"she's\", 'if', 'of', 'down', 'more', 'ain', 'theirs', 'at', 'this', 'shan', 'doing', 'during', 'after', 'that', 'y', 'which', 'their', 'against', 'hadn', 'me', \"you've\", \"it's\", 'with', 'where', 'few', 'couldn', 'hasn', 'we', 'once', 'and', 'have', \"shouldn't\", \"won't\", 'herself', \"couldn't\", 'won', 'those', 'ourselves', \"mustn't\", 'wouldn', 'be', 'were', 'was', 'when', 'do', 'can', \"don't\", \"haven't\", 'he', 'ma', 'but', 'didn', 'yourself', 'haven', 'a', 'through', 'before', 'mightn', 'what', 'you', \"doesn't\", 'himself', 'than', 'very', 't', 'mustn', \"hadn't\", 'them', 'her', 'some', 'or', 'off', 'an', 'then', \"wouldn't\", 'to', 'needn', 'hers', 'am', 'nor', 'about', 'in', 'she', 'there', 'below', \"hasn't\"}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for web-scrapping - removing HTML & XML\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text , num):\n",
    "    new_text = text.lower()\n",
    "    new_text = BeautifulSoup(new_text, \"lxml\").text\n",
    "    new_text = re.sub(r'\\([^)]*\\)', '', new_text)\n",
    "    new_text = re.sub('\"','', new_text)\n",
    "    new_text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_text.split(\" \")])    \n",
    "    new_text = re.sub(r\"'s\",\"\",new_text)\n",
    "    new_text = re.sub(\"[^a-zA-Z]\", \" \", new_text) \n",
    "    new_text = re.sub('[m]{2,}', 'mm', new_text)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in new_text.split() if not w in stopWords]\n",
    "    else:\n",
    "        tokens=new_text.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n"
   ]
  },
  {
   "source": [
    "### call the function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for t in data['Text']:\n",
    "    cleaned_data.append(text_cleaner(t , 0))\n",
    "    "
   ]
  },
  {
   "source": [
    "### print text data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "cleaned_data[ :5]"
   ]
  },
  {
   "source": [
    "### now clean-up summary data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(text_cleaner(s ,1))\n",
    "print(clean_summary[:5])"
   ]
  },
  {
   "source": [
    "### adding the clean text and clean summary in data table\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = cleaned_data\n",
    "data['clean_summary'] = clean_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Id                        88351\n",
       "ProductId                 88351\n",
       "UserId                    88351\n",
       "ProfileName               88351\n",
       "HelpfulnessNumerator      88351\n",
       "HelpfulnessDenominator    88351\n",
       "Score                     88351\n",
       "Time                      88351\n",
       "Summary                   88351\n",
       "Text                      88351\n",
       "clean_text                88351\n",
       "clean_summary             88351\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "import numpy as np\n",
    "data.replace('', np.NaN, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "\n",
    "data.count()"
   ]
  },
  {
   "source": [
    "## Understanding the distribution of the sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 388.0125 263.63625\" width=\"388.0125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 263.63625 \r\nL 388.0125 263.63625 \r\nL 388.0125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.0125 239.758125 \r\nL 191.577717 239.758125 \r\nL 191.577717 22.318125 \r\nL 46.0125 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 52.629101 239.758125 \r\nL 57.040168 239.758125 \r\nL 57.040168 143.553376 \r\nL 52.629101 143.553376 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 57.040168 239.758125 \r\nL 61.451235 239.758125 \r\nL 61.451235 32.672411 \r\nL 57.040168 32.672411 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 61.451235 239.758125 \r\nL 65.862302 239.758125 \r\nL 65.862302 59.780244 \r\nL 61.451235 59.780244 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 65.862302 239.758125 \r\nL 70.27337 239.758125 \r\nL 70.27337 89.866485 \r\nL 65.862302 89.866485 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 70.27337 239.758125 \r\nL 74.684437 239.758125 \r\nL 74.684437 129.805215 \r\nL 70.27337 129.805215 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 74.684437 239.758125 \r\nL 79.095504 239.758125 \r\nL 79.095504 163.733172 \r\nL 74.684437 163.733172 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 79.095504 239.758125 \r\nL 83.506571 239.758125 \r\nL 83.506571 191.801433 \r\nL 79.095504 191.801433 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 83.506571 239.758125 \r\nL 87.917638 239.758125 \r\nL 87.917638 208.247427 \r\nL 83.506571 208.247427 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 87.917638 239.758125 \r\nL 92.328706 239.758125 \r\nL 92.328706 218.272577 \r\nL 87.917638 218.272577 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 92.328706 239.758125 \r\nL 96.739773 239.758125 \r\nL 96.739773 239.758125 \r\nL 92.328706 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_13\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 96.739773 239.758125 \r\nL 101.15084 239.758125 \r\nL 101.15084 226.571114 \r\nL 96.739773 226.571114 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 101.15084 239.758125 \r\nL 105.561907 239.758125 \r\nL 105.561907 231.783329 \r\nL 101.15084 231.783329 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 105.561907 239.758125 \r\nL 109.972974 239.758125 \r\nL 109.972974 234.891233 \r\nL 105.561907 234.891233 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 109.972974 239.758125 \r\nL 114.384042 239.758125 \r\nL 114.384042 236.88763 \r\nL 109.972974 236.88763 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_17\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 114.384042 239.758125 \r\nL 118.795109 239.758125 \r\nL 118.795109 238.085468 \r\nL 114.384042 238.085468 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_18\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 118.795109 239.758125 \r\nL 123.206176 239.758125 \r\nL 123.206176 239.024314 \r\nL 118.795109 239.024314 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_19\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 123.206176 239.758125 \r\nL 127.617243 239.758125 \r\nL 127.617243 239.196976 \r\nL 123.206176 239.196976 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_20\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 127.617243 239.758125 \r\nL 132.02831 239.758125 \r\nL 132.02831 239.348054 \r\nL 127.617243 239.348054 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_21\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 132.02831 239.758125 \r\nL 136.439377 239.758125 \r\nL 136.439377 239.445176 \r\nL 132.02831 239.445176 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_22\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 136.439377 239.758125 \r\nL 140.850445 239.758125 \r\nL 140.850445 239.758125 \r\nL 136.439377 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_23\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 140.850445 239.758125 \r\nL 145.261512 239.758125 \r\nL 145.261512 239.563881 \r\nL 140.850445 239.563881 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_24\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 145.261512 239.758125 \r\nL 149.672579 239.758125 \r\nL 149.672579 239.55309 \r\nL 145.261512 239.55309 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_25\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 149.672579 239.758125 \r\nL 154.083646 239.758125 \r\nL 154.083646 239.63942 \r\nL 149.672579 239.63942 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_26\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 154.083646 239.758125 \r\nL 158.494713 239.758125 \r\nL 158.494713 239.628629 \r\nL 154.083646 239.628629 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_27\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 158.494713 239.758125 \r\nL 162.905781 239.758125 \r\nL 162.905781 239.704168 \r\nL 158.494713 239.704168 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_28\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 162.905781 239.758125 \r\nL 167.316848 239.758125 \r\nL 167.316848 239.736542 \r\nL 162.905781 239.736542 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_29\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 167.316848 239.758125 \r\nL 171.727915 239.758125 \r\nL 171.727915 239.747334 \r\nL 167.316848 239.747334 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_30\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 171.727915 239.758125 \r\nL 176.138982 239.758125 \r\nL 176.138982 239.758125 \r\nL 171.727915 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_31\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 176.138982 239.758125 \r\nL 180.550049 239.758125 \r\nL 180.550049 239.758125 \r\nL 176.138982 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_32\">\r\n    <path clip-path=\"url(#pd1515026f0)\" d=\"M 180.550049 239.758125 \r\nL 184.961117 239.758125 \r\nL 184.961117 239.747334 \r\nL 180.550049 239.747334 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 47.727915 239.758125 \r\nL 47.727915 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6bff853697\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.727915\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(44.546665 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 96.739773 239.758125 \r\nL 96.739773 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.739773\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(90.377273 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 145.75163 239.758125 \r\nL 145.75163 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.75163\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(139.38913 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 239.758125 \r\nL 191.577717 239.758125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mfddab47638\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(32.65 243.557344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 212.779788 \r\nL 191.577717 212.779788 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"212.779788\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 2500 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(13.5625 216.579007)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 185.801451 \r\nL 191.577717 185.801451 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"185.801451\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 5000 -->\r\n      <g transform=\"translate(13.5625 189.60067)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 158.823114 \r\nL 191.577717 158.823114 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"158.823114\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 7500 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(13.5625 162.622333)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 131.844777 \r\nL 191.577717 131.844777 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"131.844777\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 10000 -->\r\n      <g transform=\"translate(7.2 135.643996)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 104.86644 \r\nL 191.577717 104.86644 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"104.86644\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 12500 -->\r\n      <g transform=\"translate(7.2 108.665659)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 77.888103 \r\nL 191.577717 77.888103 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"77.888103\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15000 -->\r\n      <g transform=\"translate(7.2 81.687322)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 50.909766 \r\nL 191.577717 50.909766 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"50.909766\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 17500 -->\r\n      <g transform=\"translate(7.2 54.708985)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#pd1515026f0)\" d=\"M 46.0125 23.93143 \r\nL 191.577717 23.93143 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#mfddab47638\" y=\"23.93143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 20000 -->\r\n      <g transform=\"translate(7.2 27.730648)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_33\">\r\n    <path d=\"M 46.0125 239.758125 \r\nL 46.0125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_34\">\r\n    <path d=\"M 191.577717 239.758125 \r\nL 191.577717 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_35\">\r\n    <path d=\"M 46.0125 239.758125 \r\nL 191.577717 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_36\">\r\n    <path d=\"M 46.0125 22.318125 \r\nL 191.577717 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_13\">\r\n    <!-- summary -->\r\n    <defs>\r\n     <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n     <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n     <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n     <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n     <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n    </defs>\r\n    <g transform=\"translate(90.483546 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"52.099609\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"115.478516\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"212.890625\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"310.302734\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"371.582031\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"412.695312\" xlink:href=\"#DejaVuSans-121\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_37\">\r\n    <path d=\"M 235.247283 239.758125 \r\nL 380.8125 239.758125 \r\nL 380.8125 22.318125 \r\nL 235.247283 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"patch_38\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 241.863883 239.758125 \r\nL 246.274951 239.758125 \r\nL 246.274951 32.672411 \r\nL 241.863883 32.672411 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_39\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 246.274951 239.758125 \r\nL 250.686018 239.758125 \r\nL 250.686018 181.145495 \r\nL 246.274951 181.145495 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_40\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 250.686018 239.758125 \r\nL 255.097085 239.758125 \r\nL 255.097085 224.560558 \r\nL 250.686018 224.560558 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_41\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 255.097085 239.758125 \r\nL 259.508152 239.758125 \r\nL 259.508152 234.746929 \r\nL 255.097085 234.746929 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_42\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 259.508152 239.758125 \r\nL 263.919219 239.758125 \r\nL 263.919219 237.744464 \r\nL 259.508152 237.744464 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_43\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 263.919219 239.758125 \r\nL 268.330287 239.758125 \r\nL 268.330287 238.889037 \r\nL 263.919219 238.889037 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_44\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 268.330287 239.758125 \r\nL 272.741354 239.758125 \r\nL 272.741354 239.305543 \r\nL 268.330287 239.305543 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_45\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 272.741354 239.758125 \r\nL 277.152421 239.758125 \r\nL 277.152421 239.548232 \r\nL 272.741354 239.548232 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_46\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 277.152421 239.758125 \r\nL 281.563488 239.758125 \r\nL 281.563488 239.659738 \r\nL 277.152421 239.659738 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_47\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 281.563488 239.758125 \r\nL 285.974555 239.758125 \r\nL 285.974555 239.692533 \r\nL 281.563488 239.692533 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_48\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 285.974555 239.758125 \r\nL 290.385623 239.758125 \r\nL 290.385623 239.708931 \r\nL 285.974555 239.708931 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_49\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 290.385623 239.758125 \r\nL 294.79669 239.758125 \r\nL 294.79669 239.731888 \r\nL 290.385623 239.731888 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_50\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 294.79669 239.758125 \r\nL 299.207757 239.758125 \r\nL 299.207757 239.741727 \r\nL 294.79669 239.741727 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_51\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 299.207757 239.758125 \r\nL 303.618824 239.758125 \r\nL 303.618824 239.741727 \r\nL 299.207757 239.741727 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_52\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 303.618824 239.758125 \r\nL 308.029891 239.758125 \r\nL 308.029891 239.751566 \r\nL 303.618824 239.751566 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_53\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 308.029891 239.758125 \r\nL 312.440958 239.758125 \r\nL 312.440958 239.751566 \r\nL 308.029891 239.751566 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_54\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 312.440958 239.758125 \r\nL 316.852026 239.758125 \r\nL 316.852026 239.754845 \r\nL 312.440958 239.754845 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_55\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 316.852026 239.758125 \r\nL 321.263093 239.758125 \r\nL 321.263093 239.758125 \r\nL 316.852026 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_56\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 321.263093 239.758125 \r\nL 325.67416 239.758125 \r\nL 325.67416 239.758125 \r\nL 321.263093 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_57\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 325.67416 239.758125 \r\nL 330.085227 239.758125 \r\nL 330.085227 239.758125 \r\nL 325.67416 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_58\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 330.085227 239.758125 \r\nL 334.496294 239.758125 \r\nL 334.496294 239.748286 \r\nL 330.085227 239.748286 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_59\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 334.496294 239.758125 \r\nL 338.907362 239.758125 \r\nL 338.907362 239.758125 \r\nL 334.496294 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_60\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 338.907362 239.758125 \r\nL 343.318429 239.758125 \r\nL 343.318429 239.758125 \r\nL 338.907362 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_61\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 343.318429 239.758125 \r\nL 347.729496 239.758125 \r\nL 347.729496 239.758125 \r\nL 343.318429 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_62\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 347.729496 239.758125 \r\nL 352.140563 239.758125 \r\nL 352.140563 239.758125 \r\nL 347.729496 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_63\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 352.140563 239.758125 \r\nL 356.55163 239.758125 \r\nL 356.55163 239.758125 \r\nL 352.140563 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_64\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 356.55163 239.758125 \r\nL 360.962698 239.758125 \r\nL 360.962698 239.758125 \r\nL 356.55163 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_65\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 360.962698 239.758125 \r\nL 365.373765 239.758125 \r\nL 365.373765 239.758125 \r\nL 360.962698 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_66\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 365.373765 239.758125 \r\nL 369.784832 239.758125 \r\nL 369.784832 239.758125 \r\nL 365.373765 239.758125 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"patch_67\">\r\n    <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 369.784832 239.758125 \r\nL 374.195899 239.758125 \r\nL 374.195899 239.754845 \r\nL 369.784832 239.754845 \r\nz\r\n\" style=\"fill:#1f77b4;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 241.649233 239.758125 \r\nL 241.649233 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.649233\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(238.467983 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_27\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 295.311851 239.758125 \r\nL 295.311851 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"295.311851\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 500 -->\r\n      <g transform=\"translate(285.768101 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_29\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 348.974469 239.758125 \r\nL 348.974469 22.318125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_30\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"348.974469\" xlink:href=\"#m6bff853697\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 1000 -->\r\n      <g transform=\"translate(336.249469 254.356563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_31\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 239.758125 \r\nL 380.8125 239.758125 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_32\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(221.884783 243.557344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_33\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 206.962338 \r\nL 380.8125 206.962338 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_34\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"206.962338\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 10000 -->\r\n      <g transform=\"translate(196.434783 210.761557)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_35\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 174.166552 \r\nL 380.8125 174.166552 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_36\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"174.166552\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 20000 -->\r\n      <g transform=\"translate(196.434783 177.965771)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_37\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 141.370765 \r\nL 380.8125 141.370765 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_38\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"141.370765\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 30000 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(196.434783 145.169984)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_39\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 108.574979 \r\nL 380.8125 108.574979 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_40\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"108.574979\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 40000 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(196.434783 112.374198)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_41\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 75.779192 \r\nL 380.8125 75.779192 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_42\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"75.779192\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 50000 -->\r\n      <g transform=\"translate(196.434783 79.578411)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_43\">\r\n      <path clip-path=\"url(#p2ff51c3ea3)\" d=\"M 235.247283 42.983406 \r\nL 380.8125 42.983406 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_44\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.247283\" xlink:href=\"#mfddab47638\" y=\"42.983406\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 60000 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(196.434783 46.782625)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_68\">\r\n    <path d=\"M 235.247283 239.758125 \r\nL 235.247283 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_69\">\r\n    <path d=\"M 380.8125 239.758125 \r\nL 380.8125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_70\">\r\n    <path d=\"M 235.247283 239.758125 \r\nL 380.8125 239.758125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_71\">\r\n    <path d=\"M 235.247283 22.318125 \r\nL 380.8125 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_24\">\r\n    <!-- text -->\r\n    <defs>\r\n     <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n     <path d=\"M 54.890625 54.6875 \r\nL 35.109375 28.078125 \r\nL 55.90625 0 \r\nL 45.3125 0 \r\nL 29.390625 21.484375 \r\nL 13.484375 0 \r\nL 2.875 0 \r\nL 24.125 28.609375 \r\nL 4.6875 54.6875 \r\nL 15.28125 54.6875 \r\nL 29.78125 35.203125 \r\nL 44.28125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-120\"/>\r\n    </defs>\r\n    <g transform=\"translate(296.187391 16.318125)scale(0.12 -0.12)\">\r\n     <use xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"98.982422\" xlink:href=\"#DejaVuSans-120\"/>\r\n     <use x=\"158.162109\" xlink:href=\"#DejaVuSans-116\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pd1515026f0\">\r\n   <rect height=\"217.44\" width=\"145.565217\" x=\"46.0125\" y=\"22.318125\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p2ff51c3ea3\">\r\n   <rect height=\"217.44\" width=\"145.565217\" x=\"235.247283\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "text_word_count =[]\n",
    "summary_word_count = []\n",
    "\n",
    "for i in data['clean_text']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "\n",
    "for j in data['clean_summary']:\n",
    "    summary_word_count.append(len(j.split()))\n",
    "\n",
    "\n",
    "#representing data in graph\n",
    "length_df = pd.DataFrame({'text' : text_word_count , 'summary' : summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Let us understand the proportion of the length of summaries below 8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The percentage of summaries with lenght less than 9 is :: 0.9425020656246109\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in data['clean_summary']:\n",
    "    if(len(i.split())  < 9):\n",
    "        cnt = cnt +1\n",
    "print(\"The percentage of summaries with lenght less than 9 is ::\" ,  cnt / len(data['clean_summary']))"
   ]
  },
  {
   "source": [
    "### let's check for text data for 30 lenght "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the percentage of the data with length less or equal 30 is :::  0.682493689941257\n"
     ]
    }
   ],
   "source": [
    "te_cnt = 0\n",
    "for i in data['clean_text']:\n",
    "    if(len(i.split()) <= 40):\n",
    "        te_cnt =te_cnt +1\n",
    "print(\"the percentage of the data with length less or equal 30 is ::: \" , te_cnt/len(data['clean_text']))"
   ]
  },
  {
   "source": [
    "### we got that data with max lenght is about 50 % and with max length 40 is about 68 %. But here we have smaller machine for training so we choose max text length 30 data. because with lots of data the neural netwoo some time overfit so it will decrease accuracy\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### so we decide that our system will give summary of atleast 9 words\n",
    "### as well as we decide to take max length of text is 30"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 30\n",
    "max_summary_length = 8"
   ]
  },
  {
   "source": [
    "### so here we separate the data which text has max_lenght is 30 and summary have less then 9 lenght"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data-set Creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = np.array(data['clean_text'])\n",
    "clean_summary = np.array(data['clean_summary']) \n",
    "\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(clean_text)):\n",
    "    if(len(clean_text[i].split()) <= max_text_length and len(clean_summary[i].split()) <= max_summary_length):\n",
    "        short_text.append(clean_text[i])\n",
    "        short_summary.append(clean_summary[i])\n",
    "\n",
    "df = pd.DataFrame({'text' : short_text , 'summary' : short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text                                     summary\n",
       "0      bought several vitality canned dog food produc...                       good quality dog food\n",
       "1      product arrived labeled jumbo salted peanuts p...                           not as advertised\n",
       "2      looking secret ingredient robitussin believe f...                              cough medicine\n",
       "3      great taffy great price wide assortment yummy ...                                 great taffy\n",
       "4      saltwater taffy great flavors soft chewy candy...  great just as good as the expensive brands\n",
       "...                                                  ...                                         ...\n",
       "47165  stuff awesome best flavor boil water drain wat...                                 great stuff\n",
       "47166               love noodle little spicy wife perfct                                  good stuff\n",
       "47167                 love buy another box done last one                                       yummy\n",
       "47168  favorite brand korean ramen spicy used eating ...                                 great ramen\n",
       "47169  like noodles although say spicy somewhat under...                                       spicy\n",
       "\n",
       "[47170 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bought several vitality canned dog food produc...</td>\n      <td>good quality dog food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>product arrived labeled jumbo salted peanuts p...</td>\n      <td>not as advertised</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking secret ingredient robitussin believe f...</td>\n      <td>cough medicine</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>great taffy great price wide assortment yummy ...</td>\n      <td>great taffy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>saltwater taffy great flavors soft chewy candy...</td>\n      <td>great just as good as the expensive brands</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47165</th>\n      <td>stuff awesome best flavor boil water drain wat...</td>\n      <td>great stuff</td>\n    </tr>\n    <tr>\n      <th>47166</th>\n      <td>love noodle little spicy wife perfct</td>\n      <td>good stuff</td>\n    </tr>\n    <tr>\n      <th>47167</th>\n      <td>love buy another box done last one</td>\n      <td>yummy</td>\n    </tr>\n    <tr>\n      <th>47168</th>\n      <td>favorite brand korean ramen spicy used eating ...</td>\n      <td>great ramen</td>\n    </tr>\n    <tr>\n      <th>47169</th>\n      <td>like noodles although say spicy somewhat under...</td>\n      <td>spicy</td>\n    </tr>\n  </tbody>\n</table>\n<p>47170 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "### now we are inserting spacial tokan at the \"starting\"  and  \"ending\" of the summary.\n",
    "### here we choose 'sostok' as start tokan & 'eostok' for end tokan."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text                                            summary\n",
       "0      bought several vitality canned dog food produc...                sostok good quality dog food eostok\n",
       "1      product arrived labeled jumbo salted peanuts p...                    sostok not as advertised eostok\n",
       "2      looking secret ingredient robitussin believe f...                       sostok cough medicine eostok\n",
       "3      great taffy great price wide assortment yummy ...                          sostok great taffy eostok\n",
       "4      saltwater taffy great flavors soft chewy candy...  sostok great just as good as the expensive bra...\n",
       "...                                                  ...                                                ...\n",
       "47165  stuff awesome best flavor boil water drain wat...                          sostok great stuff eostok\n",
       "47166               love noodle little spicy wife perfct                           sostok good stuff eostok\n",
       "47167                 love buy another box done last one                                sostok yummy eostok\n",
       "47168  favorite brand korean ramen spicy used eating ...                          sostok great ramen eostok\n",
       "47169  like noodles although say spicy somewhat under...                                sostok spicy eostok\n",
       "\n",
       "[47170 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bought several vitality canned dog food produc...</td>\n      <td>sostok good quality dog food eostok</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>product arrived labeled jumbo salted peanuts p...</td>\n      <td>sostok not as advertised eostok</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>looking secret ingredient robitussin believe f...</td>\n      <td>sostok cough medicine eostok</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>great taffy great price wide assortment yummy ...</td>\n      <td>sostok great taffy eostok</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>saltwater taffy great flavors soft chewy candy...</td>\n      <td>sostok great just as good as the expensive bra...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47165</th>\n      <td>stuff awesome best flavor boil water drain wat...</td>\n      <td>sostok great stuff eostok</td>\n    </tr>\n    <tr>\n      <th>47166</th>\n      <td>love noodle little spicy wife perfct</td>\n      <td>sostok good stuff eostok</td>\n    </tr>\n    <tr>\n      <th>47167</th>\n      <td>love buy another box done last one</td>\n      <td>sostok yummy eostok</td>\n    </tr>\n    <tr>\n      <th>47168</th>\n      <td>favorite brand korean ramen spicy used eating ...</td>\n      <td>sostok great ramen eostok</td>\n    </tr>\n    <tr>\n      <th>47169</th>\n      <td>like noodles although say spicy somewhat under...</td>\n      <td>sostok spicy eostok</td>\n    </tr>\n  </tbody>\n</table>\n<p>47170 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x :'sostok ' + x + ' eostok')\n",
    "df"
   ]
  },
  {
   "source": [
    "### deviding dataset into text and train set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42453 4717 42453 4717\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr , x_val , y_tr , y_val = train_test_split( np.array(df['text']) , np.array(df['summary']) ,test_size = 0.1 , random_state = 0 , shuffle = True)\n",
    "print(len(x_tr) , len(x_val) , len(y_tr) , len(y_val) )"
   ]
  },
  {
   "source": [
    "## Convert words data in numarical form (preparing TOKENIZER)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Text Summarizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24934\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "print(len(x_tokenizer.word_counts.items()))\n"
   ]
  },
  {
   "source": [
    "## Rarewords and its Coverage\n",
    "### Let us look at the proportion rare words and its total coverage in the entire text\n",
    "\n",
    "### Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "% of rare words in vocabulary: 66.14261650758002\nTotal Coverage of rare words: 2.956306874516583\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0 #gives me the no. of rare words whose count falls below threshold\n",
    "tot_cnt=0 #gives the size of vocabulary (which means every unique words in the text)\n",
    "freq=0\n",
    "tot_freq=0\n",
    "##tot_cnt --> cnt gives me the top most common words\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "source": [
    "### Let us define the tokenizer with top most common words for reviews.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8443"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#first we create tokeniser for reviews on the training dataset\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt - cnt)\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert the string sequence into integer sequence\n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr)\n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding 0 upto the max_seq_len in both dataset , so that we can pass it through neural network\n",
    "x_tr = pad_sequences(x_tr_seq , maxlen=max_text_length , padding='post')\n",
    "x_val = pad_sequences(x_val_seq , maxlen=max_text_length , padding= 'post')\n",
    "\n",
    "#size of dictonary \n",
    "x_voc = x_tokenizer.num_words + 1\n",
    "\n",
    "x_voc"
   ]
  },
  {
   "source": [
    "##############################################################################################################################"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Summary Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the tokenizer for reviews of the data\n",
    "\n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "source": [
    "## Rarewords and its Coverage\n",
    "### Let us look at the proportion rare words and its total coverage in the entire summary\n",
    "\n",
    "### Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "% of the rare words in vocabulary is  78.12981298129813\ntotal coverage of the rare words is  5.392639775441626\n"
     ]
    }
   ],
   "source": [
    "thresh = 6\n",
    "\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "freq = 0\n",
    "tot_freq = 0\n",
    "\n",
    "\n",
    "for key , value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt +1 \n",
    "    tot_freq = tot_freq + value\n",
    "    if(value < thresh):\n",
    "        cnt = cnt +1 \n",
    "        freq = freq+value\n",
    "\n",
    "\n",
    "\n",
    "#printing the percentage of the rare words & coverage of the rare words\n",
    "print(\"% of the rare words in vocabulary is \" , (cnt/tot_cnt)*100)\n",
    "print(\"total coverage of the rare words is \" , (freq /tot_freq)*100)"
   ]
  },
  {
   "source": [
    "### Let us define the tokenizer with top most common words for summary.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "#preparing the tokenizer for reviews on training dataset\n",
    "y_tokenizer = Tokenizer(num_words= tot_cnt - cnt)\n",
    "y_tokenizer.fit_on_texts(y_tr)\n",
    "\n",
    "#convert data & summary text string into numbers sequence\n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr)\n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "#padding 0 upto max length\n",
    "y_tr = pad_sequences(y_tr_seq , maxlen=max_summary_length , padding = \"post\")\n",
    "y_val = pad_sequences(y_val_seq , maxlen = max_summary_length , padding= \"post\")\n",
    "\n",
    "#size of the vocabulary \n",
    "y_voc  = y_tokenizer.num_words +1\n",
    "\n",
    "y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42453 42453\n"
     ]
    }
   ],
   "source": [
    "# check length of that the count of the tokan \"sostok\" and len(y_tr) are equal\n",
    "\n",
    "print(y_tokenizer.word_counts['sostok'] , len(y_tr))\n"
   ]
  },
  {
   "source": [
    "### now we need to delete the rows containing only start and end tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41346 41346\n"
     ]
    }
   ],
   "source": [
    "# first deleting from training dataset\n",
    "ind = []\n",
    "for i in range(len(y_tr)):\n",
    "    cnt = 0\n",
    "    for j in y_tr[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt +1\n",
    "    if(cnt == 2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr = np.delete(y_tr , ind , axis=0)\n",
    "x_tr = np.delete(x_tr , ind , axis = 0)\n",
    "print(len(y_tr) , len(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4717 4717\n"
     ]
    }
   ],
   "source": [
    "#now we are deleting from testing dataset (validation)\n",
    "\n",
    "ind = []\n",
    "for i in range(len(y_val)):\n",
    "    cnt = 0\n",
    "    for j in range(len(y_val[i])):\n",
    "        if(j != 0):\n",
    "            cnt = cnt +1\n",
    "    if(cnt == 2):\n",
    "        ind.append(i)\n",
    "\n",
    "\n",
    "x_val = np.delete(x_val , ind , axis = 0)\n",
    "y_val = np.delete(y_val , ind , axis = 0)\n",
    "print(len(x_val) , len(y_val))\n"
   ]
  },
  {
   "source": [
    "## Model Building\n",
    "### We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
    "\n",
    "### Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "\n",
    "Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "\n",
    "Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
    "\n",
    "Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
    "\n",
    "## Here, we are building a 3 stacked LSTM for the encoder:\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed , Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "\n",
    "from attention import Attention\n",
    "from keras import backend as k\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 30)]         0                                            \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 30, 100)      844300      input_5[0][0]                    \n__________________________________________________________________________________________________\nlstm_8 (LSTM)                   [(None, 30, 300), (N 481200      embedding_4[0][0]                \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nlstm_9 (LSTM)                   [(None, 30, 300), (N 721200      lstm_8[0][0]                     \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, None, 100)    198900      input_6[0][0]                    \n__________________________________________________________________________________________________\nlstm_10 (LSTM)                  [(None, 30, 300), (N 721200      lstm_9[0][0]                     \n__________________________________________________________________________________________________\nlstm_11 (LSTM)                  [(None, None, 300),  481200      embedding_5[0][0]                \n                                                                 lstm_10[0][1]                    \n                                                                 lstm_10[0][2]                    \n__________________________________________________________________________________________________\nattention_layer (AttentionLayer ((None, None, 300),  180300      lstm_10[0][0]                    \n                                                                 lstm_11[0][0]                    \n__________________________________________________________________________________________________\nconcat_layer (Concatenate)      (None, None, 300)    0           lstm_11[0][0]                    \n                                                                 attention_layer[0][0]            \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, None, 1989)   598689      concat_layer[0][0]               \n==================================================================================================\nTotal params: 4,226,989\nTrainable params: 4,226,989\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim = 100\n",
    "\n",
    "#encoder\n",
    "encoder_inputs = Input(shape=(max_text_length))\n",
    "\n",
    "#embedding layer\n",
    "enc_emd = Embedding(x_voc , embedding_dim , trainable = True)(encoder_inputs)\n",
    "\n",
    "#encode LSTM layer 1\n",
    "encoder_lstm1= LSTM(latent_dim , return_sequences = True , return_state= True , dropout= 0.4 , recurrent_dropout = 0.4)\n",
    "encoder_output1 , state_h1 ,state_c1 = encoder_lstm1(enc_emd)\n",
    "\n",
    "#encode LSTM layer 2\n",
    "encoder_lstm2 = LSTM(latent_dim , return_sequences=True, return_state=True , dropout = 0.4 , recurrent_dropout = 0.4)\n",
    "encoder_output2 , state_h2 , state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encode LSTM layer 3\n",
    "encoder_lstm3 = LSTM(latent_dim , return_sequences= True , return_state=True , dropout = 0.4 , recurrent_dropout = 0.4)\n",
    "encoder_outputs , state_h , state_c = encoder_lstm3(encoder_output2)\n",
    "\n",
    "#setup decoder , using encoder as intial state\n",
    "decoder_inputs = Input(shape=(None , ))\n",
    "\n",
    "#embedding layer\n",
    "dec_emd_layer = Embedding( y_voc , embedding_dim , trainable = True)\n",
    "dec_emb = dec_emd_layer(decoder_inputs)\n",
    "\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim , return_sequences =True , return_state = True , dropout = 0.4 , recurrent_dropout = 0.4 )\n",
    "decoder_outputs , decoder_fwd_state , decoder_back_state  = decoder_lstm(dec_emb , initial_state = [state_h , state_c])\n",
    "\n",
    "#attention layer\n",
    "attn_layer = AttentionLayer(name = 'attention_layer')\n",
    "attn_out , attn_state  = attn_layer([encoder_outputs , decoder_outputs])\n",
    "\n",
    "#concat attention input and dence output LSTM \n",
    "decoder_concat_input = Concatenate(axis = 1 , name = 'concat_layer'  )([decoder_outputs , attn_out])\n",
    "\n",
    "#dence layer\n",
    "decoder_dence = TimeDistributed(Dense(y_voc , activation='softmax'))\n",
    "decoder_outputs = decoder_dence(decoder_concat_input)\n",
    "\n",
    "#define model\n",
    "model = Model([encoder_inputs , decoder_inputs] , decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}